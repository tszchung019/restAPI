<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Speech Recognition</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
        background-color: #f4f4f4;
    }
    .container {
        text-align: center;
    }
    button {
        padding: 10px 20px;
        font-size: 16px;
        background-color: #007bff;
        color: #fff;
        border: none;
        cursor: pointer;
        border-radius: 5px;
    }
    button:hover {
        background-color: #0056b3;
    }
    .transcript {
        margin-top: 20px;
        font-size: 20px;
    }
</style>
</head>
<body>
<div class="container">
    <label for="audioData">Upload .wav file:</label>
    <input type="file" id="audioData" name="audioData">
    <br>
    <button id="sendRequest">Send</button>
    <div id="transcript" class="transcript"></div>
    <div id="response" class="response"></div>
</div>
<script>
    async function getWeather(location) {
        try {
            location = location || "Sheffield";

            const url = `https://api.weatherapi.com/v1/current.json?key=127ab19806704d10886145828240304&q=${location}`;
            const response = await fetch(url);

            if (!response.ok) {
                throw new Error(`Failed to fetch weather data for ${location}.`);
            }

            const data = await response.json();
            document.getElementById('response').textContent = `It is ${data.current.condition.text} in ${data.location.name}.`;
        } catch (error) {
            console.error('Error:', error.message);
            document.getElementById('response').textContent = `Failed to fetch weather data: ${error.message}`;
        }
    }

    function intentAction(data) {
        const regex = /\{(?:[^{}]*|\{(?:[^{}]*|\{[^{}]*\})*\})*\}/g;
        const jsonObjects = data.match(regex);
        const finalUnderstanding = JSON.parse(jsonObjects[jsonObjects.length - 1]);
        document.getElementById('transcript').textContent = `Transcript: ${finalUnderstanding.text}`;

        switch (finalUnderstanding.intents[0].name) {
            case "greeting":
                document.getElementById('response').textContent = "Hello, nice to meet you!";
                break;
            case "wit$get_weather":
                if (finalUnderstanding.entities['wit$location:location'] && finalUnderstanding.entities['wit$location:location'].length > 0) {
                    getWeather(finalUnderstanding.entities['wit$location:location'][0].body);
                } else {
                    getWeather();
                }
                break;
        }
    }

    document.getElementById('sendRequest').addEventListener('click', async function() {
        const fileInput = document.getElementById('audioData');
        const file = fileInput.files[0];

        if (!file) {
            alert("Please select a file.");
            return;
        }

        if (file.type !== 'audio/wav') {
            alert("Please select a .wav file.");
            return;
        }

        const formData = new FormData();
        formData.append('audio', file);

        try {
            const response = await fetch('https://api.wit.ai/speech?v=20240403', {
                method: 'POST',
                headers: {
                    'Content-type': 'audio/wav',
                    'Authorization': `Bearer 3E3ZO7ZJOMNSPKZ7BMWZEJV7PVCXVSLB`
                },
                body: formData.get('audio')
            });

            if (!response.ok) {
                throw new Error('Failed to recognize speech');
            }

            const data = await response.text();
            intentAction(data);
        } catch (error) {
            console.error('Error:', error);
        }
    });
</script>
</body>
</html>
